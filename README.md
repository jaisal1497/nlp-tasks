This repository is a part of my Natural Language Processing course at Plaksha. There were 4 tasks, All the tasks are executed using pyTorch. Task 1 was to create a preprocessing pipeline for NLP tasks and build a bag of words model to classify movie reviews. Task 2 involved creating N-gram language models on wikipedia text with about 100 million tokens. Second part involved creating wa word2vec model using gensim to classify sentiments of movie reviews. Task 3 involved fine-tuning BERT for classification tasks. Task 4 involved fine-tuning a mBERT on a Natural Language Inference task. Fine-tuned the model on English Training data and then evaluate the performance of the models on different languages to demonstrate zero-shot learning capabilities of BERT. 
